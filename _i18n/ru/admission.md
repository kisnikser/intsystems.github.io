## Слушателям отдельных курсов

1. Приходите, слушайте, участвуйте.
2. Вся информация о текущих курсах доступна в [канале](https://t.me/IS_MIPT).
3. Ведомости на кафедру идут из деканата, оформляйте их там.
4. Курсы требуют подготовки, поэтому
   - уточните у преподавателей возможность присоединиться к курсу,
   - в течение первых недель поймите, сможете ли вы сдать курс.
5. Узнайте, что требуется для сдачи курса.

<!--# Поступление в магистратуру: весна 2022 -->
<!-- # Распределение студентов на специализацию «Интеллектуальный анализ данных» -->
<!-- * Весна 2022: Собеседование 18 апреля в 17:00 по адресу [m1p.org/go_zoom](https://m1p.org/go_zoom)
* [Список выступающих тут](https://docs.google.com/spreadsheets/d/1dU-QU9wTlV-V3nvOg8lQFxKHJo72F4I1vDZN031imUY/edit?usp=sharing) -->
<!-- Собеседование 4 курса (МФТИ и внешние) состоится в **мае, июне, июле** по запросу на mlalgorithms(at)gmail.com. -->

## Поступление на кафедру

**Формат поступления:** собеседование

### Алгоритм поступления, 2-3 курсы, бакалавры

1. студент заполняет [анкету](http://bit.ly/1lFrFha),
2. решает одну из нижеприведенных задач (четвертый курс рассказывает о дипломной работе),
3. составляет мнение о работах, которые выполняют студенты кафедры,
4. в назначенную дату делает трехминутный доклад о задаче и о заинтересовавшей теме или работе,
5. в тот же день вечером получает решение кафедры,
6. ждет распоряжение деканата о распределении на кафедру.

### Процедура собеседования 3 курса с точки зрения преподавателей

1. cобираем всю группу желающих поступить на кафедру,
2. слушаем краткий доклад каждого участника

- «решение тестовой задачи»,
- «мои цели при поступлении на кафедру» на материале студенческих работ кафедры,

3. задаем вопросы, смотрим анкету,
4. составляем ранжированный список поступающих, публикуем [по ссылке тут] и отправляем в деканат.

Материалы

1. [дипломные работы](https://is-mipt.site/ru/materials/thesis/), [отчеты НИР](https://is-mipt.site/ru/materials/nir/),
2. [презентации магистров](https://www.youtube.com/watch?v=f4C9U59krTE&t=39s), [презентации бакалавров](https://www.youtube.com/watch?v=mmAacGSUvPQ)

### Пробные задачи осень 2025 и более ранние

Можно использовать не только задачи текущего года, но и задачи прошлых лет.

#### Осень 2024

**Задача 64**
Визуализировать алгоритм [Гершберга-Сакстона](https://en.wikipedia.org/wiki/Gerchberg%E2%80%93Saxton_algorithm) для двумерных изображений. Рассказать о двумерном преобразовании Фурье, об исходном и целевом пространствах и о сходимости в них.

**Задача 63**
Рассказать о способах численного решения обыкновенных дифференциальных уравнений с иллюстрациями на реальных данных измерений. Желательно включить Adjoint State Method.

**Задача 62**
Рассказать о методе Галеркина на примере реальных данных. Заменить линейную модель на двухслойную нейросеть. Показать разницу в решении. Визуализировать данные и модель.

**Задача 61**
Рассказать о методе конечных элементов на с примером на реальных данных (уравнение эластичности, Пуассона, другие уравнения в частных производных по вашему выбору). Визуализировать различные подходы, для линейных моделей и нейросетей.

**Задача 60**
Проиллюстрировать алгоритм снижения размерности пространства в методе Галеркина при решении уравнения Навье-Стокса с иллюстрацией на реальных или синтетических данных.

**Задача 59**
Проиллюстрировать алгоритм снижения размерности на данных двумерной компьютерной томографии, линейная модель (и нейросеть по выбору).

**Задача 58**
Рассказать о прогнозировании сегмента временного ряда методом [сингулярного анализа спектра](https://ru.wikipedia.org/wiki/SSA_(%D0%BC%D0%B5%D1%82%D0%BE%D0%B4)) ([английская версия](https://en.wikipedia.org/wiki/Singular_spectrum_analysis)). Проанализировать исходную размерность матрицы Ганкеля и ее сниженную размерность.

**Задача 57**
Рассказать о том, чем преобразование Фурье более высоких порядков (с тензорным представлением данных) отличается от одномерного преобразования. Проиллюстрировать мультфильмом низкого разрешения (или похожими данными; в прямом и обратном преобразовании со снижением качества).

**Задача 56**
Сравнить классические методы численного решения уравнений в частных производных (эллиптических, параболических, гиперболических) и нейросетевые приближения решений на реальных данных.

**Задача 55**
Задан временной ряд IMU мобильного телефона (акселерометр, гироскоп). Телефон лежит на груди человека. Предложить алгоритм декомпозиции почти-периодических колебаний (пульс, дыхание, случайные движения).

**Задача 54**
Задано два временных ряда, определить, являются ли они связанными (causal inference), с помощью метода [Сходящихся перекрестных отображений](https://en.wikipedia.org/wiki/Convergent_cross_mapping). Проанализировать размерности пространств.

#### Осень 2023

**Задача 54**
Найти задачу из [Pen and Paper Exercises in Machine Learning by Michael U. Gutmann](https://arxiv.org/abs/2206.13446) и разобрать ее решение (проиллюстрировать графиком в коде).

**Задача 55**
В задаче логистической регрессии найти оптимальные параметры модели (любая небольшая выборка под регрессию из UCI, пример из sklearn). Используюя случайные подвыбоки найти ковариацию параметров.

**Задача 56**
В задаче автогеррессионного прогнозирования оценить (теоретически), насколько отчетов времени вперед можно сделать прогноз с дисперсией, не превышающей заданную. Дисперсию ошибки и прогноза можно оценить. Нарисовать график с осями "время момента прогноза, дисперсия прогноза".

**Задача 57**
Проанализировать компромисс отклонение-дисперсия (bias-variance tradeoff) для случая разных типов распределений (желательно включая мультимодальные), нарисовать иллюстранцию на простых синтетических данных.

#### Осень 2022

**Задача 53**
Видео, например, мультфильм с шагающим персонажем – трехиндексная матрица. Требуется выполнить низкоранговое разложение (например HOSVD), и показать оптимальное число одноранговых трехиндексных матриц, необходимое для восстановления. Можно воспользоваться сингулярными числами (главными компонентами) и [методом сломанной трости](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82#.D0.9E.D1.86.D0.B5.D0.BD.D0.BA.D0.B0_.D1.87.D0.B8.D1.81.D0.BB.D0.B0_.D0.B3.D0.BB.D0.B0.D0.B2.D0.BD.D1.8B.D1.85_.D0.BA.D0.BE.D0.BC.D0.BF.D0.BE.D0.BD.D0.B5.D0.BD.D1.82_.D0.BF.D0.BE_.D0.BF.D1.80.D0.B0.D0.B2.D0.B8.D0.BB.D1.83_.D1.81.D0.BB.D0.BE.D0.BC.D0.B0.D0.BD.D0.BD.D0.BE.D0.B9_.D1.82.D1.80.D0.BE.D1.81.D1.82.D0.B8). Каким образом можно снизить не только размерность пространства, но и число индексов матрицы? Например зная, что герой идет от одного края сцены к другому.

**Задача 52**
Даны работа [Pedro Domingos](https://arxiv.org/abs/2012.00152), лекция [Воронцова про SVM](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%9A.%D0%92.%D0%92%D0%BE%D1%80%D0%BE%D0%BD%D1%86%D0%BE%D0%B2%29). Требуется визуализировать Figure 1 на простой выборке, которая аппроксимируется 1) линейной моделью, 2) нейросетью. Возможно размерность пространства независимой переменной $x$ равна один, размерность пространства параметров $w$ равна два. Доработать график так, чтобы показать на нем ось $x$ и ось $K$ и даже ось $L$ (надо думать, как, цветом или в несколько графиков). При этом ось $K$ это или само ядро или путь ядра по $t$. Формулы и рисунки в [файле](http://www.machinelearning.ru/wiki/images/d/dc/Is_problem_52.pdf).

**Задача 51**
Похожая задача в [файле](http://www.machinelearning.ru/wiki/images/3/3c/Is_problem_51.pdf).

**Задача 50**
Задана выборка и модель классификации или регрессии, несложная. Требуется оценить и визуализировать матрицу ковариации параметров. Для линейных моделей оценка получается [МНК](https://math.stackexchange.com/questions/4082033/deriving-the-variance-covariance-matrix-for-parameter-vector-of-a-linear-regress). Для линейных моделей и нейросетей оценка получается, например, с помощью процедуры бутстреп. Семплируем подвыборку, равномощную выборке (с повторениями). Оцениваем (оптимизируем) параметры на этой подвыборке, получая набор векторов параметров. Оцениваем ковариационную матрицу. Нарисовать полученную матрицу. Нарисовать зависимость ошибки от пары параметров, например, как [тут](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5:ModelBreadSw.png).

**Задача 49**
Обосновать и показать на примере почему повышать число слоев нейросети предпочтительнее, с точки зрения точности аппроксимации, чем повышать число нейронов скрытого слоя. Использовать теоремы Колмогорова, Цыбенкова, Ханина: [1](https://github.com/MarkPotanin/GeneticOpt/blob/master/Potanin2019NNStructure_APX.pdf), см. также [2](https://www.overleaf.com/project/5e5c03d8be38d600013535c3).

**Задача 48**
Предыдущая задача на следующих даных: по видео маятника часов восстановить и нарисовать фазовое пространство и интегральную кривую решения уравнения маятника. Насколько решение математической модели маятника совпадает с координатами маятника на видео?

**Задача 47**
Показать, что движения конечностей человека адекватно аппроксимируются моделью маятника (если покажете, что системой маятников, вообще замечательно). Модель задана в виде ОДУ, решением ОДУ является интегральная кривая. Требуется снять показания акселерометра и гироскопа своего мобильного телефона, или двух телефонов, в руке, сумке, кармане (это маятник), или найти готовые. Нарисовать эти показания в фазовом пространстве "скорость-ускорение" или можно построить пространство по другому, на ваш вкус. Решить ОДУ – модель маятника, нарисовать решение ОДУ в том же пространстве. Запустить код Neural ODE, аппроксимировать показания, нарисовать решение в том же пространстве [1](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D0%BF%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_%28%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B8%2C_%D0%90.%D0%92._%D0%93%D1%80%D0%B0%D0%B1%D0%BE%D0%B2%D0%BE%D0%B9%2C_%D0%92.%D0%92._%D0%A1%D1%82%D1%80%D0%B8%D0%B6%D0%BE%D0%B2%29/%D0%9E%D1%81%D0%B5%D0%BD%D1%8C_2021).

**Задача 46**
Задана выборка для метрической классификации (kNN). Как изменится точность классификации при увеличении числа ближайших соседей? На обучении, на контроле? Как найти оптимальное число соседей? Что изменится, если вместо евклидова расстояния использовать расстояние Махаланобиса x'Ax. Как получить оптимальный метрический тензор A?

**Задача 45**
Задана выборка для классификации или для регрессии. На случайных подвыборках оценить матожидание и дисперсию функции ошибки (точность прогноза). Оценить матожидание и ковариации элементов вектора параметров. Как изменяются все эти оценки при 1) снижении объема выборки, 2) снижении сложности модели? Нарисовать графики. Модель – линейная или логистическая регрессия. Сложность – число параметров. (Вариант с нейросетью.)

**Задача 44**
Задана выборка для классификации и модель решающего дерева. На случайных подвыборках алгоритм построения дерева, например С 4.5, строит различные деревья. Как можно вычислить расстояние между двумя деревьями? Насколько разные деревья возвращает алгоритм построения дерева? Визуализировать значения функции парного расстояния? Насколько различные деревья возвращает алгоритм построения леса решающих деревьев?

**Задача 43**
Для акселерометров двух мобильных телефонов в руке или в кармане во время ходьбы: прогнозировать значения одного по другому (метод partial least squares, canonic correlation analysis). Насколько вырастет ошибка прогноза значений гироскопа по акселерометру? Или значения акселерометра в кармане по значению акселерометра в руке?

#### Весна 2021

**Задача 42**
Алгоритм [Герхберга-Сакстона](https://en.wikipedia.org/wiki/Gerchberg%E2%80%93Saxton_algorithm) восстанавливает мнимую часть изображения по его действительной части. Итеративно выполняем прямое и обратное преобразование Фурье. После первого же преобразования появляется мнимая часть. Продолжаем до тех пор, пока ошибка реконструкции изображения в комплексном пространстве не стабилизируется. Этот алгоритм используется для восстановления синхротронных изображений кристаллов по амплитуде плоского когерентного излучения. Вопрос: можно ли таким образом повысить качество изображения с обычного фотоаппарата? Дополнение. Так как этот алгоритм был предложен в 1972 году, существуют его модификации. Если вспомнить, что преобразование Фурье линейно, то в качестве альтернативы рассмотрим нелинейное преобразование, например, автоэнкодер. 

**Задача 41**
Процедура обучения модели, иначе процедура оптимизации ее параметров, описывает пошаговое изменение вектора параметров. Так как вектор параметров – это точка в пространстве параметров, то процедура описывает пошаговое преобразование пространства параметров. Цель процедуры – получение оптимального значения вектора параметров. Эта процедура имеет различные варианты.

- Детерминированная оптимизация – градиентный спуск, например, методом сопряженных градиентов.
- Стохастический градиентный спуск. Градиент вычисляется по случайно взятой подвыборке.
- Случайный поиск и варианты генетической оптимизации.
- Теоретико-игровая оптимизация: процедура является реализацией игровой стратегии.
- Дистилляция знаний: модель-ученик оптимизирует параметры с помощью фиксированной модели-учителя.
- Гиперсети: одна модель прогнозирует значения параметров другой.
  
Предлагается описать на выбор интересный, нетривиальный способ обучения модели и проиллюстрировать его графиками на синтетических данных.

**Задача 40**
Возможно ли сложную модель, например, глубокую нейросеть, обучить на выборке, которая содержит всего несколько элементов? Как определить оптимальный объем выборки? Как определить оптимальную сложность модели? Как согласовать эти две величины?

**Задача 39**
В задаче восстановления регрессии предполагается, что распределение зависимой переменной унимодально. А точнее, нормально. А как решить задачу восстановления регрессии, когда это распределение мультимодально (привести такие случаи)? Например, рассмотрим восстановления зависимой переменной, для выборки $(\mathbf{x}_i, y_i),\quad i\in\{1, \dots, N\}$,  где неслучайная величина $\mathbf{x}\in\mathbb{C}$ — комплексное число, а зависимая переменная, случайная величина  $y\in\mathbb{R}$ — действительное число, измеренное с некоторой погрешностью. Объем $N$ выборки достаточно велик. Требуется восстановить модель $f=\ln(\mathbf{x})$ (вставьте оптимизируемые параметры по вашему усмотрению). Сама независимая переменная может быть представлена в полярной форме, например $\mathbf{x} = r\exp(i\theta),\quad r>0,\quad \theta =\phi\pm 2\pi, 4\pi, \dots$. Предложить параметрическую модель, оценить параметры (можно и их дисперсию), нарисовать трехмерный график и проанализировать случай, когда погрешность велика.

**Задача 38**
Сейчас у каждого человека при себе один телефон, а то и несколько. Пусть один в кармане, другой в руке а третий в сумке. Возможно ли по значениям временного ряда акселерометров (или гироскопов) двух телефонов спрогнозировать значение временного ряда третьего? Нарисовать фазовые траектории временных рядов телефонов (для ходьбы или бега или подъема по лестнице) и проанализировать методы Partial least squares, либо Cross correlation analysis.

**Задача 37**
Глубокая нейронная сеть (композиция нескольких слоев) имеет меньшее число нейронов по сравнению с альтернативной ей сетью с одним скрытым слоем. При этом качество аппроксимации не падает. Почему это происходит? Визуализируйте траекторию вектора параметров в пространстве параметров в процессе оптимизации сети. Рекомендуется использовать для визуализации пространство низкой размерности, 2D или 3D.

**Задача 36**
Метод Лассо выбирает признаки в линейной модели с помощью регуляризатора. При этом значения параметров модели зависят от назначенного значения регуляризатора. Вопрос: а как изменяются дисперсии параметров? Почему именно так? (Бонус: Что изменяется в распределениях параметров, если для выбора признаков используется метод Эластик-нет?)

**Задача 35**
Эксперты оценивают качество университетов путем 1) попарного сравнения, 2) по некоторой шкале (например, пятибалльной). Некоторые оценки отсутствуют. Требуется построить рейтинг университетов, который не меняется существенно в течение лет (конечно, при отсутствии изменений в политике университетов). Примеры решения 1) считаем попарную корреляцию между оценками и строим первую главную компоненту, 2) метод Кемени-Янга. Предлагается выписать и проанализировать эти решения или предложить свое.

**Задача 34**
Следует ли метод аппроксимации Лапласа из теоремы Бернштейна-фон Мизеса?

**Задача 33**
Сверточные нейросети CNN: как связана свертка, кросс-корреляция и преобразование Фурье? Пояснить на примере изображений.

#### Весна 2020

Про задачу kNN уже больше не надо рассказывать, перебор...

**Задача 21**
Предсказание площади лесных пожаров. На основе погодных измерений необходимо предсказать объем выгоревших лесных массивов на севере Португалии. Выборка состоит из 13 признаков и 517 объектов. Для решения задачи предлагается использовать [метод наименьших квадратов](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2) с регуляризацией. Нарисовать график весов признаков и общей ошибки на кросс-валидации при изменении параметра регуляризации. Какие признаки наиболее важны для нашей задачи? Что изменится, если предварительно все признаки стандартизовать?

**Задача 20**
В крупную сеть гипермаркетов ежедневно выполняются поставки различных товаров. Требуется, использую временную историю спроса бананов за один год [Goods](https://sourceforge.net/p/mlalgorithms/code/HEAD/tree/Group274/Dvinskikh2016Essays/TestProgramming/Data_data.mat), построить прогноз спроса товара на неделю. Для прогнозирования предлагается использовать алгоритм Гусеница, или SSA (Singular spectrum analysis).

**Задача 19**
Классификация [ядовитости грибов](https://archive.ics.uci.edu/dataset/73/mushroom) по основным признакам. Построить модель классификации на основе [сети радиальных базисных функций](http://www.machinelearning.ru/wiki/index.php?title=RBF). В качестве функции ошибки использовать метрику HEOM.

**Задача 18**
Распознавание [британских гласных](https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass.html) (11 штук) по данным с динамиков, рекомендуется использовать нормированные признаки (файл .scaled). Решить задачу многоклассовой классификации с помощью решающего дерева. Реализовать метод решающего дерева, построить область разделения на классы в проекции на любые 2 признака.

**Задача 17**
Идентификация видов стекла. Часто на месте преступления остаются осколки разных видов стекол, которые можно использовать как улики, если определить тип стекла и от каких оно объектов. Выборка состоит из 9 признаков - химических параметров образцов и 214 объектов. Необходимо каждому образцу сопоставить один из 6 классов (например: стекло автомобиля, осколок посуды, окно здания) и сравнить качество работы решающего дерева и алгоритма [решающего дерева](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D1%88%D0%B0%D1%8E%D1%89%D0%B5%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE) и алгоритма [k-ближайших соседей](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_k_%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85_%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9_%28%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D1%80%29). В качестве функции ошибки использовать долю неправильных ответов классификатора. Дает ли масштабирование признаков значительное улучшение в качестве классификации?

**Задача 16**
По описанию [условий посева](https://archive.ics.uci.edu/dataset/244/fertility) предсказать прорастут семена растений или нет. Провести бинарную классификацию семян с помощью метода Парзеновского окна. Построить график зависимости ошибки на контроле от ширины окна. Подобрать оптимальную ширину окна.

**Задача 15**
Нарисовать путь наименьшей стоимости между временными рядами, найденный с помощью алгоритма [DTW](https://sourceforge.net/p/mlalgorithms/code/HEAD/tree/Group274/Goncharov2015Centroids/code/DTW.zip?format=raw). Ввести ограничения на вид пути в матрице с помощью техники ["Sakoe-Chiba band"](https://izbicki.me/img/uploads/2011/10/Sakoe-Chiba1.png). Показать, что при наименьшей величине отклонения пути от диагонали при этих ограничениях стоимость DTW перейдет в евклидово расстояние. Исследовать зависимость стоимости пути от величины ограничения. В качестве данных использовать синтетические временные ряды вида $\sin ( x + c ) , \sin ( a  |\sin ( x ) | ) + \sin ( b x )$.

**Задача 14**
Используя данные о школьниках, выявить степень их алкогольной зависимости. В данных, взятых с UCI ['Students'](https://github.com/amanchoudhary/student-alcohol-consumption-prediction) (исходная выборка изъята из UCI, но осталась в других источниках), содержится информация о 30 признаках для каждого школьника, включая социальные и гендерные, а также указана материальная обеспеченность и количество свободного времени. Выбрать на свой взгляд наиболее весомые признаки и предсказать степень употребления алкоголя по выходным или будним по шкале от 0 до 5.

**Задача 13**
Для выделения тем на коллекции документов используется матричное разложение. Предлагается определить к каким темам относится каждая из русских народных сказок. Для это следует построить словарь для коллекции документов. Построить матрицу строками в которой являются частоты слов из словаря, а число строк равняется числу сказок в коллекции. Сделать разложение матрицы "документ-слово" на матрицы "документ-тема" и "тема-слово" методом [SVD](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D0%B8%D0%BD%D0%B3%D1%83%D0%BB%D1%8F%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D0%B7%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5). В качестве коллекции документов предлагается взять: А. Барто "Мячик", "Бычок", "Зайка". Документом считать 2 строки произведения. В качестве словаря взять 10-20 слов.

**Задача 12**
Предсказать сорт винограда из которого сделано вино, используя [результаты химических анализов](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data) (описание [данных](https://archive.ics.uci.edu/dataset/109/wine)), c помощью KNN - метода k ближайших соседей с тремя различными метриками. Построить график зависимости величины ошибки от числа соседей k.

**Задача 11**
Нарисовать траекторию пошагового спуска к минимуму градиентного метода и [имитации отжига](http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%B8%D0%BC%D0%B8%D1%82%D0%B0%D1%86%D0%B8%D0%B8_%D0%BE%D1%82%D0%B6%D0%B8%D0%B3%D0%B0). Сравнить их работу при поиске мимимума [тестовой функции](http://www.machinelearning.ru/wiki/images/8/8d/SCHWEFEL.pdf).

**Задача 10**
Задана MIDI-партитура. Требуется спрогнозировать следующую ноту как (линейную) комбинацию предыдущих. Предложить алгоритм.

**Задача 9**
Назовем двоичную, размера $M,N$, матрицу $m$-разреженной по строкам ($n$-разреженной по столбцам), если в каждой строке $m$ пропущенных значений. Пропущенные значения в строке $x$ восстанавливаются следующим образом. Находим ближайшую к ней строку $y$ (расстояние Хемминга не превышает $\rho$), и заполняем пропущенные значения. Задана случайная матрица. Чему равняется максимальное значение $n$ (или $m$), чтобы все пропущенные значения можно было бы восстановить?

**Задача 8**
В роман одного автора (Льва Толстого) поместили несколько абзацев другого (Михаила Зощенко). Предложить алгоритм, который бы находил бы смену стиля автора (кроме этого текста ничего нет, авторов мы не знаем). Можно представить текст как набор временных рядов или предложить другой способ представления текста для анализа.

**Задача 7**
Задан фрагмент музыкального произведения. Предложить быстрый (например, хеширование изображения спектрограммы звука) алгоритм поиска в музыкальной базе Shazam.

**Задача 6**
Задано плоское черно-белое изображение односвязной фигуры (клякса). Предложить алгоритм, который бы указывал группу симметрии этой фигуры, если она имеется.

**Задача 5**
Задан временной ряд с изменяющимся периодом. Предложить алгоритм, который отыскивает начало периода, пример: отсечение пика или как в [1].

**Задача 4**
Задан текст (например, «Вот дом, который построил Джек»). Преложить алгоритм, который бы по нескольким предыдущим словам прогнозировал бы следующее слово. Проанализировать ошибку прогноза.

**Задача 3**
Заданы два временных ряда. Предложить алгоритм выравнивания (DTW, [Rus](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%B4%D0%B8%D0%BD%D0%B0%D0%BC%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B9_%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9_%D1%88%D0%BA%D0%B0%D0%BB%D1%8B), [En](https://en.wikipedia.org/wiki/Dynamic_time_warping)), который ищет путь наименьшей стоимости не перебором, а методом градиентного спуска, приближая полиномом (третьей) степени.

**Задача 2**
Задана выборка измерений акселерометра [WISDM](https://www.cis.fordham.edu/wisdm/dataset.php). Модель движения из шести классов движений задается вектором средних значений сегментов нескольких повторов движений одного класса. Предложить способ классификации выборки.

**Задача 1**
Задан полносвязный граф со взвешенными ребрами. Предложить алгоритм нахождения основного дерева, который отыскивал бы это дерево путем градиентного спуска. Для этого требуется ввести дифференцируемую штрафную функцию, которая штрафует полносвязный граф за то, что он не является деревом.

#### Весна 2019

**Задача 30**
Решить задачу: классификации
На выборке: тональность [твиттер-сообщений](http://thinknook.com/wp-content/uploads/2012/09/Sentiment-Analysis-Dataset.zip).
С использованием моделей: логистическая регрессия на центроидах векторов предложений, нейронная сеть с одним скрытым слоем.
Векторы предложений: https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md
Со структурным параметром: количество итераций оптимизации нейронной сети, размер скрытого слоя.
С критериями качества: ROC AUC, precision-recall-кривая

**Задача 29**
Решить задачу: классификации
На выборке: [SemEval 2015](http://alt.qcri.org/semeval2015/task2/data/uploads/sts2015-en-post.zip).
С использованием моделей: логистическая регрессия на центроидах векторов предложений, SVM, KNN, Decision Tree.
Векторы предложений: https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md
В качестве меток класса брать округление оценок схожести (принимает значения от 0 до 5)
Со структурным параметром: глубина и структура деревьев, параметры регуляризации логистической регрессии и SVM, количество соседей в KNN
С критериями качества: Precision-Recall-кривая


**Задача 28**
Решить задачу: кластеризации/классификации
На выборке: MNIST
С использованием моделей: PCA + K-means
Со структурным параметром: количество главных компонент в PCA
С критериями качества: однородность кластеров, Accuracy (за ответ классификатора принимать наиболее представимый в кластере класс)

**Задача 27**
Решить задачу: классификации
На выборке: [celeb-a](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html), рассматривать изображения как черно-белые. В качестве метки класса рассматривать пол изображенного человека.
С использованием моделей: SVM, нейронная сеть с одним скрытым слоем.
Со структурным параметром: количество нейронов на скрытом слое, количество итераций оптимизации нейронной сети.
критерии качества: ROC AUC

**Задача 26**
Решить задачу: кластеризации
На выборке: предобученных векторов [fasttext](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md), взять только слова из [20k.txt](https://github.com/first20hours/google-10000-english/blob/master/20k.txt)
С использованием модели: K-means
Со структурным параметром: K (число кластеров)
Критерии качества: внутрикластерное расстояние (евклидово расстояние и косинусная мера), межкластерное расстояние (евклидово расстояние и косинусная мера)

**Задача 25**
Решить задачу: классификации
на выборке: синтетической и https://archive.ics.uci.edu/ml/datasets/Breast+Cancer
с использованием моделей: логистической регрессии, нейронной сети, градиентного бустинга
со структурными параметрами: состав признаков, структура модели, количество параметров модели
критерии качества: ROC AUC, PR кривая, сложность модели (ввести опеределение)

**Задача 24**
Решить задачу: выбора алгоритма оптимизации
на выборке: синтетической и MNIST
с использованием моделей: нейронных сетей простой структуры
Предлагаемые алгоритмы: SGD, Nesterov Momentum, Adam
со структурными параметрами: структура сети
критерии качества: скорость сходимости, значения оптимума, вид траектории

**Задача 23**
Решить задачу: регрессии
на выборке: синтетической и нет
с использованием моделей: линейная регрессия, PCA + линейная регрессия, простая нейросеть
со структурными параметрами: число и состав признаков, размерность скрытого пространства, структура сети
критерии качества: квадратичная ошибка, число обусловленности

**Задача 22**
Решить задачу: классификации
на выборке: синтетической и https://archive.ics.uci.edu/ml/datasets/Lung+Cancer
с использованием моделей: kNN, SVM, логистическая регрессия
со структурными параметрами: число и состав признаков,
критерии качества AUC, F1, число признаков

#### Весна 2018 и ранее

Эти задачи тоже можно решать

1. Восстановить регрессию используя формулу [Надарая-Ватсона](http://www.machinelearning.ru/wiki/index.php?title=%D0%A4%D0%BE%D1%80%D0%BC%D1%83%D0%BB%D0%B0_%D0%9D%D0%B0%D0%B4%D0%B0%D1%80%D0%B0%D1%8F-%D0%92%D0%B0%D1%82%D1%81%D0%BE%D0%BD%D0%B0). Нарисовать восстановленную функцию с различными ядрами и шириной окна. В качестве данных использовать выборку [цены на хлеб](https://sourceforge.net/projects/dmba/) или [цены на электроэнергию](https://sourceforge.net/projects/mlalgorithms/).
2. 2D визуализация [N-мерных данных](https://drive.google.com/file/d/0B3vYNXYMNm_rMDFGc1B3OS0tRGs/view?usp=sharing) с помощью [PCA](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%B3%D0%BB%D0%B0%D0%B2%D0%BD%D1%8B%D1%85_%D0%BA%D0%BE%D0%BC%D0%BF%D0%BE%D0%BD%D0%B5%D0%BD%D1%82).

### Советы по решению задач (это просто советы, а не указания)

- Теоретическое решение важнее практического.
- Пишите теорию сами (не копируйте материал лекций).
- Визуализируйте решение задач (рисунок от руки предпочтительнее его отсутствия).
- Результаты эксперимента выносите на слайды (не показывайте pynb).
- При обсуждении нейросетей учтите, что они для нас — не черные ящики, а прозрачные.
- Берите эти, или прошлые, или свои задачи – что вам самим интересно.

### Список тем для обсуждения

[Собран в разделе Список тем на этой странице](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B_%28%D0%BA%D0%B0%D1%84%D0%B5%D0%B4%D1%80%D0%B0_%D0%9C%D0%A4%D0%A2%D0%98%29/%D0%9F%D1%80%D0%B8%D0%B5%D0%BC_%D1%81%D1%82%D1%83%D0%B4%D0%B5%D0%BD%D1%82%D0%BE%D0%B2#.D0.A1.D0.BF.D0.B8.D1.81.D0.BE.D0.BA_.D1.82.D0.B5.D0.BC_.D0.B4.D0.BB.D1.8F_.D0.BA.D1.80.D0.B0.D1.82.D0.BA.D0.B8.D1.85_.D0.B4.D0.BE.D0.BA.D0.BB.D0.B0.D0.B4.D0.BE.D0.B2)

### Результаты отбора

- Публикуются на следующий день после отбора в канале кафедры [@IS_MIPT](https://t.me/IS_MIPT).

## Процедура приема в магистратуру

1. студент заполняет [анкету](http://bit.ly/1lFrFha),
2. cобираем желающих поступить на кафедру по запросам от них,
3. смотрим анкету, дипломную работу, спрашиваем мнение о теме и работах студентов кафедры, задаем вопросы по [математической части](https://arxiv.org/abs/2206.13446) бакалаврской программы Разделы 1, 2, 3 из Pen and Paper Exercises in Machine Learning by Michael U. Gutmann

Цель собеседования – понять,

1. каков вклад студент внесет в научную работу кафедры
2. соответствует ли квалификация студента уровню планируемых диссетраций магистров.

## Научная работа на кафедре

Ваша научная квалификация – ваша основная цель на кафедре. Кафедра фокусируется на математических основах машинного обучения. Это означает, что ваша работа фокусируется на развитии теоретических методов. Вы получаете теоретические результаты. Практические приложения для иллюстрации ваших результатов в вычислительном эксперименте могут быть произвольными.

Научное сотрудничество и обмен идеями являются основой научной работы. Не стесняйтесь писать исследователям и рассказывать о себе и своих результатах и планах. Цель научного руководителя для вас – показать верное направление для исследований, дать тему, поставить задачу в общем. Надо понимать, что руководитель работает в своей тематике. Как узнать тематику? В [scholar.google.com](https://scholar.google.com/scholar?q=Vadim+Strijov&hl=en&as_sdt=0%2C5&as_ylo=2022&as_yhi=2019) забить фамилию руководителя, посмотреть работы последних лет. Попросить у руководителя задачу.

Требования к научному руководителю:

1. доктор или кандидат наук,
2. работает в тематике кафедры и держит связь с кафедрой.

Кафедра не может назначить вам научного руководителя. Его надо найти путем общения и договоренности о совместной работе. Когда будете искать научных руководителей, рассказывайте о себе: каковы ваша квалификация, достижения, научные работы, планы.

Совет. Ищите научных руководителей в исследовательских группах. Если Вас интересуют

- тематическое моделирование, информационный поиск, анализ новостей, то это группа проф. Константина Вячеславовича Воронцова,
- математика, оптимизация, управление, математическое моделирование, то это группа проф. Александра Владимировича Гасникова,
- технологии создания систем искусственного интеллекта, анализ изображений и видео, то это группа проф. Ивана Алексеевича Матвеева,
- генеративные модели, геометрическое глубокое обучение, выбор моделей, анализ сигналов, то это группа проф. Вадима Викторовича Стрижова,
- чистая и дискретная математика, продвинутая комбинаторика, то это группа проф. Андрея Михайловича Райгородского.

Найдите участников этих научных групп. Посмотрите тематику их научных статей последних лет. Составьте список соавторов. Посмотрите прикрепленный PDF. Напишите потенциальным руководителям. Важный совет. Свяжитесь со студентами и аспирантами Вашей специальности. Спросите их как они организуют работу с научными руководителями.

Для быстрого представления начальных результатов постарайтесь принять участие в студенческих конференциях [пример](https://conf.mipt.ru).

### Что надо сделать:

1. Посмотреть кто был успешным научруком:

- [дипломные работы](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B_%28%D0%BA%D0%B0%D1%84%D0%B5%D0%B4%D1%80%D0%B0_%D0%9C%D0%A4%D0%A2%D0%98%29/%D0%A1%D1%82%D1%83%D0%B4%D0%B5%D0%BD%D1%82%D1%8B),
- [отчеты и формат НИР](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D1%8B_%28%D0%BA%D0%B0%D1%84%D0%B5%D0%B4%D1%80%D0%B0_%D0%9C%D0%A4%D0%A2%D0%98%29/%D0%9E%D1%82%D1%87%D0%B5%D1%82%D1%8B_%D0%9D%D0%98%D0%A0),
- [преподаватели кафедры](http://is-mipt.site),
- [защиты бакалаврских работ](https://www.youtube.com/watch?v=mmAacGSUvPQ),
- [защиты магистериских](https://www.youtube.com/watch?v=f4C9U59krTE),
- [защиты кандидатских](https://www.youtube.com/playlist?list=PLk4h7dmY2eYGO1lczVHclXnv0f-CvUkXO).

2. Посоветоваться со студентами и аспирантами. Почитать [руководство](http://www.machinelearning.ru/wiki/index.php?title=%D0%9D%D0%B0%D1%83%D1%87%D0%BD%D0%BE-%D0%B8%D1%81%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%28%D1%80%D0%B5%D0%BA%D0%BE%D0%BC%D0%B5%D0%BD%D0%B4%D0%B0%D1%86%D0%B8%D0%B8%29).
3. Найти научного руководителя (по вашему стилю мышления и интересам).
4. Попросить его **связаться с кафедрой** и утвердить тему работы.
5. Начать работу с ним и представить ее результаты на зачетной неделе в начале сессии.
6. Формат отчетности [статья, презентация, код](https://intsystems.github.io/ru/materials/nir/).

### Когда надо это сделать:

1. Третий курс ищет научруков в течение весеннего семестра и сообщает об этом на зачете то НИР.
2. Пятый курс имеет научрука в начале осеннего семестра (мы спрашиваем о планах).
3. Аспиранты имеют публикации с научруком.

Совет. Менять научрука и тему в любой момент – это нормально: вы развиваетесь, приоритеты изменяются. Желательно доделывать проекты, чтобы было что показать. Работать с несколькими научруками по разным темам – замечательно (если успеваете). Работать в командах – прекрасно, важен ваш личный вклад.
